{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Intro to PyTorch - CIFAR10 Dataset.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "359b6de046d047d68ca271138388b6c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9fac57bb9b81468d92d4cd815af5145f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_af9275a70aeb4b9f851e22b91de02913",
              "IPY_MODEL_56bbd45ba6244c078ea43395e1fea811"
            ]
          }
        },
        "9fac57bb9b81468d92d4cd815af5145f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "af9275a70aeb4b9f851e22b91de02913": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8eadf9c7bf5a4cf6a979bbf275a4b0aa",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 170498071,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 170498071,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4e9a3db7c06746cc97ebbf83507e374f"
          }
        },
        "56bbd45ba6244c078ea43395e1fea811": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0def4825311c42689ea3be015bb25802",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170499072/? [01:53&lt;00:00, 1504835.60it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_33f51258cd9044009f7c27034dfaf6e6"
          }
        },
        "8eadf9c7bf5a4cf6a979bbf275a4b0aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4e9a3db7c06746cc97ebbf83507e374f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0def4825311c42689ea3be015bb25802": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "33f51258cd9044009f7c27034dfaf6e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZoM8P2kxbFn_"
      },
      "source": [
        "This is an introductory notebook exploring building a simple neural network via PyTorch for the CIFAR-10 dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4yjZb4_bCd4"
      },
      "source": [
        "import torch #pytorch package\r\n",
        "import torchvision #package that deals with datasets and pretrained neural nets\r\n",
        "import torch.utils.data\r\n",
        "import torchvision.transforms as transforms"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbhQ9Ygebibq"
      },
      "source": [
        "# defining a transformation of images to torch tensors, using transforms.ToTensor()\r\n",
        "# defining the values for standardizing the images, the mean and standard deviation for each channel using pre-computed numbers\r\n",
        "\r\n",
        "transform = transforms.Compose(\r\n",
        "    [transforms.ToTensor(),\r\n",
        "     transforms.Normalize( (0.4914, 0.48216, 0.44653), (0.24703, 0.24349, 0.26159) )]) #3 channels because RGB, Normalize(Mean, STD)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AfcY3elOcfLC"
      },
      "source": [
        "After importing the necessary packages and defining a function to transform the image dataset to tensors, we now import the CIFAR10 dataset as trainset and testset tensors using the transform function from the previous cell.\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117,
          "referenced_widgets": [
            "359b6de046d047d68ca271138388b6c5",
            "9fac57bb9b81468d92d4cd815af5145f",
            "af9275a70aeb4b9f851e22b91de02913",
            "56bbd45ba6244c078ea43395e1fea811",
            "8eadf9c7bf5a4cf6a979bbf275a4b0aa",
            "4e9a3db7c06746cc97ebbf83507e374f",
            "0def4825311c42689ea3be015bb25802",
            "33f51258cd9044009f7c27034dfaf6e6"
          ]
        },
        "id": "R_F0pDZmcB8n",
        "outputId": "affde67e-3c6a-4d7a-83ac-237d344d8cef"
      },
      "source": [
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download = True, transform = transform)\r\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download = True, transform = transform)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "359b6de046d047d68ca271138388b6c5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=170498071.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BtV_dd-OdXNv"
      },
      "source": [
        "We now build trainloader and testloader to get the data ready for PyTorch. We set the minibatch to 32  to use 32  images per iteration (due to ds size). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8qZ29lIc_8h"
      },
      "source": [
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size = 32, shuffle = True, num_workers = 2)\r\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size = 32, shuffle = False, num_workers= 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59KezepDeQpG"
      },
      "source": [
        "Now we can inspect the dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFcv-8kodt6u",
        "outputId": "75b90189-6e77-4dee-a97d-736fb155f31a"
      },
      "source": [
        "# print(testloader.dataset.test_data.shape, trainloader.dataset.train_data.shape)\r\n",
        "\r\n",
        "print(\"Shape of test data: \", testloader.dataset.data.shape, )\r\n",
        "print(\"Batch size of test data: \",testloader.batch_size)\r\n",
        "print(\"Shape of train data: \", trainloader.dataset.data.shape, )\r\n",
        "print(\"Batch size of train data: \",trainloader.batch_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of test data:  (10000, 32, 32, 3)\n",
            "Batch size of test data:  32\n",
            "Shape of train data:  (50000, 32, 32, 3)\n",
            "Batch size of train data:  32\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YNUaE5r_ePlC"
      },
      "source": [
        "Now we write the class for the neural network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tcheCGwze8IF"
      },
      "source": [
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F #use this to apply ReLU non linearity in the hidden layer\r\n",
        "import torch.optim as optim\r\n",
        "\r\n",
        "class Net(nn.Module):\r\n",
        "  def __init__(self):\r\n",
        "    super(Net,self).__init__()\r\n",
        "    self.fc1 = nn.Linear(32*32*3, 500) #image shape (32,32,3) // we set the no. of units in this hidden layer to be 500\r\n",
        "    self.fc2 = nn.Linear(500,10)\r\n",
        "\r\n",
        "  def forward(self, x):\r\n",
        "    x = F.relu(self.fc1(x))\r\n",
        "    return self.fc2(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0g7aLOGGSdd"
      },
      "source": [
        "We then train the actual neural network. First, we initiate the net, the loss (cross-entropy) and the optimizer (Adam). Adam optimizer works very well + is a version of gradient descent."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwGqu2kRe7wO"
      },
      "source": [
        "\r\n",
        "net = Net()\r\n",
        "criterion = nn.CrossEntropyLoss()\r\n",
        "optimizer = optim.Adam(net.parameters(), lr=3e-4)\r\n",
        "\r\n",
        "for epoch in range(10): #loop over the dataset multiple times\r\n",
        "  for i,data in enumerate(trainloader,0):\r\n",
        "    #get the inputs\r\n",
        "    inputs, labels = data\r\n",
        "    inputs = inputs.view(-1, 32*32*3) #converts all the entries of the images into vectors\r\n",
        "\r\n",
        "    # Zero the parameter gradients - in order to not accumulate gradients from the previous iterations\r\n",
        "    optimizer.zero_grad()\r\n",
        "\r\n",
        "    #Forward + backward + optimize\r\n",
        "    outputs = net(inputs)\r\n",
        "    loss = criterion(outputs, labels)\r\n",
        "    loss.backward() #compute the gradient using loss.backward()\r\n",
        "    optimizer.step() #changing the weights using our optimizer with the optimizer.step() command"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kAo3sFh_Hs7X"
      },
      "source": [
        "After training the neural network, we then try and use the it to make predictions from our test data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uikf-fVvHuRa"
      },
      "source": [
        "correct, total = 0,0\r\n",
        "predictions = []\r\n",
        "net.eval()\r\n",
        "\r\n",
        "for i, data in enumerate(testloader,0):\r\n",
        "  inputs,labels = data\r\n",
        "  inputs = inputs.view(-1, 32*32*3)\r\n",
        "  outputs = net(inputs)\r\n",
        "  _, predicted = torch.max(outputs.data,1) #get the class with the highest score using the max function\r\n",
        "  predictions.append(outputs)\r\n",
        "  total += labels.size(0)\r\n",
        "  correct += (predicted == labels).sum().item()\r\n",
        "\r\n",
        "print('The testing set accuracy of the network is %d %%' % (100 * correct/total)) #compute for the accuracy of your classifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dzKiZ2GeHuNW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fcmsn4PcHuES"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9V0BwIisHtxz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}