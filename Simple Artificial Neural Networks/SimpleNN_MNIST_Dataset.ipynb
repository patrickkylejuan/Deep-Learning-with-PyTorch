{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Intro to PyTorch - MNIST Dataset.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGLNOcN2fO-N"
      },
      "source": [
        "import torch #pytorch package\r\n",
        "import torchvision #package that deals with datasets and pretrained neural nets\r\n",
        "import torch.utils.data\r\n",
        "import torchvision.transforms as transforms"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFGvwAi5gmvX"
      },
      "source": [
        "# Transform the data to torch tensors and normalize it \r\n",
        "transform = transforms.Compose([transforms.ToTensor(),\r\n",
        "\t\t\t\t\t\t\t\ttransforms.Normalize((0.1307), ((0.3081)))])\r\n",
        "\r\n",
        "# Prepare the datasets\r\n",
        "trainset = torchvision.datasets.MNIST('mnist', train=True, \r\n",
        "\t\t\t\t\t\t\t\t\t  download=True, transform=transform)\r\n",
        "testset = torchvision.datasets.MNIST('mnist', train=False, \r\n",
        "\t\t\t\t\t\t\t\t\t  download=True, transform=transform)\r\n",
        "\r\n",
        "# Prepare the dataloaders\r\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32,\r\n",
        "\t\t\t\t\t\t\t\t\t\t  shuffle=True, num_workers=0)\r\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=32,\r\n",
        "\t\t\t\t\t\t\t\t\t\t shuffle=False, num_workers=0)       "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KmIqPsgKgqFA"
      },
      "source": [
        "# Compute the shape of the training set and testing set\r\n",
        "trainset_shape = trainloader.dataset.train_data.shape\r\n",
        "testset_shape = testloader.dataset.test_data.shape\r\n",
        "\r\n",
        "# Print the computed shapes\r\n",
        "print(trainset_shape, testset_shape)\r\n",
        "\r\n",
        "# Compute the size of the minibatch for training set and testing set\r\n",
        "trainset_batchsize = trainloader.batch_size\r\n",
        "testset_batchsize = testloader.batch_size\r\n",
        "\r\n",
        "# Print sizes of the minibatch\r\n",
        "print(trainset_batchsize, testset_batchsize)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzbgXFq0iari"
      },
      "source": [
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F #use this to apply ReLU non linearity in the hidden layer\r\n",
        "import torch.optim as optim\r\n",
        "\r\n",
        "# Define the class Net\r\n",
        "class Net(nn.Module):\r\n",
        "    def __init__(self):    \r\n",
        "    \t# Define all the parameters of the net\r\n",
        "        super(Net, self).__init__()\r\n",
        "        self.fc1 = nn.Linear(28 * 28 * 1, 200)\r\n",
        "        self.fc2 = nn.Linear(200,10)\r\n",
        "\r\n",
        "    def forward(self, x):   \r\n",
        "    \t# Do the forward pass\r\n",
        "        x = F.relu(self.fc1(x))\r\n",
        "        x = self.fc2(x) #doesnt need relu bc this is the final layer lol\r\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMoBPn3PKo-U"
      },
      "source": [
        "# Instantiate the network, the Adam optimizer and Cross-Entropy loss function\r\n",
        "model = Net()   \r\n",
        "optimizer = optim.Adam(model.parameters(), lr=3e-4)\r\n",
        "criterion = nn.CrossEntropyLoss()\r\n",
        "\r\n",
        "for batch_idx, data_target in enumerate(train_loader):\r\n",
        "    data = data_target[0]\r\n",
        "    target = data_target[1]\r\n",
        "    data = data.view(-1, 28 * 28)\r\n",
        "    optimizer.zero_grad()\r\n",
        "\r\n",
        "    # Complete a forward pass\r\n",
        "    output = model(data)\r\n",
        "\r\n",
        "    # Compute the loss, gradients and change the weights\r\n",
        "    loss = criterion(output, target)\r\n",
        "    loss.backward()\r\n",
        "    optimizer.step()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2UiJSeoMNbi"
      },
      "source": [
        "# Set the model in eval mode\r\n",
        "model.eval()\r\n",
        "\r\n",
        "for i, data in enumerate(test_loader, 0):\r\n",
        "    inputs, labels = data\r\n",
        "    \r\n",
        "    # Put each image into a vector\r\n",
        "    inputs = inputs.view(-1, 28*28*1)\r\n",
        "    \r\n",
        "    # Do the forward pass and get the predictions\r\n",
        "    outputs = model(inputs)\r\n",
        "    _, outputs = torch.max(outputs.data, 1)\r\n",
        "    total += labels.size(0)\r\n",
        "    correct += (outputs == labels).sum().item()\r\n",
        "print('The testing set accuracy of the network is: %d %%' % (100 * correct / total))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}